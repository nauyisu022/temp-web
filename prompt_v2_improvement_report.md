# Prompt V2 迭代改进报告

> **项目名称：** KSP（Key Selling Points）生成系统  
> **迭代版本：** V1 → V2  
> **迭代日期：** 2026-02-11  
> **报告日期：** 2026-02-26  

---

## 📋 执行摘要

本次 Prompt 迭代从 **"忠实提取原文信息"** 转向 **"生成搜索友好的卖点关键词"**，目标是最大化搜索词覆盖率，同时保持每个词都与产品相关。

### 核心改进成果

| 改进维度 | 具体成果 |
|---------|---------|
| **指令长度** | Step 3 从 190 行精简至 110 行（**减少 42%**） |
| **结构化程度** | 所有步骤统一使用 JSON 输出，提升解析可靠性 |
| **指令矛盾** | 消除 3 处 P0 级别的指令矛盾 |
| **搜索导向** | 允许同义词扩展，预期搜索覆盖率提升 15-25% |
| **鲁棒性** | 增加边界情况处理，明确语言策略 |

---

## 🎯 迭代目标与设计原则

### V1 的核心问题

经过系统性分析，V1 版本存在 **22 个问题**，其中 P0 级别问题 2 个：

1. **指令矛盾**：brand 数量要求、创造新词 vs 排列组合、翻译 vs 不翻译等多处矛盾
2. **竞品分析不现实**：要求在无竞品数据的情况下做竞品差异分析，鼓励模型幻觉

### V2 的设计原则

```
1. 语言约束：所有关键词必须使用 title/description 中的语言（当地语言）
2. 搜索导向：优先使用消费者会搜索的词，允许同义词扩展
3. 灵活度梯度：brand 严格提取 > USP 允许同义词 > 长尾词最灵活
4. 精简指令：用示例驱动，减少规则堆叠
```

---

## 📊 逐步改进对照

### Step 1: 用户画像 → 用户搜索意图

#### 改进内容

| 维度 | V1 | V2 | 改进效果 |
|------|----|----|---------|
| **任务定位** | 生成用户画像（人口统计、消费心理等） | 分析用户搜索意图（搜什么词、什么场景） | ✅ 更贴近下游任务需求 |
| **输出格式** | 纯文本（"用户画像：... 选中Schema：..."） | 结构化 JSON（user_intent + search_word_types + selected_schema） | ✅ 解析可靠性提升 |
| **分析维度** | 4 个维度（人口统计、消费心理、使用场景、价值偏好），但最终要求 100 字以内 | 3 个维度（搜索意图、搜索词类型、属性选择），直接指导关键词生成 | ✅ 维度与约束匹配 |
| **对下游价值** | 画像信息对关键词提取引导有限 | 搜索意图直接指导关键词生成方向 | ✅ 信息传递效率提升 |

#### 示例对比

**V1 输出（纯文本）：**
```
用户画像：25-40岁的年轻父母，中高收入，注重食品安全和便利性...
选中Schema：材质, 容量, 加热制热, 安全保护, 用途...
```

**V2 输出（JSON）：**
```json
{
  "user_intent": "寻找安全、便携的婴儿食品储存方案",
  "search_word_types": ["材质安全词", "容量规格词", "便携性词", "用途场景词"],
  "selected_schema": ["材质", "容量", "安全保护", "用途", "便携性"]
}
```

#### 解决的 V1 问题
- ✅ **问题 #1**：非结构化输出导致下游解析不可靠
- ✅ **问题 #2**：分析维度过多但约束不足

---

### Step 2: 关键词摘抄 → 搜索关键词提取与扩展

#### 改进内容

| 维度 | V1 | V2 | 改进效果 |
|------|----|----|---------|
| **核心约束** | "必须是原文中明确存在的内容"<br>"不要同义词替换" | "语义必须来自商品信息，但表述可以用同义词" | ✅ 搜索覆盖率提升 |
| **数量要求** | 每个属性 1-3 个 | 每个属性 2-4 个，鼓励同义词变体 | ✅ 关键词丰富度提升 |
| **边界说明** | 无明确边界示例 | 明确的边界示例（✓ 保鮮袋 ✗ 抗菌） | ✅ 减少越界幻觉 |
| **无效指令** | 包含"防止循环思考"指令 | 移除无效指令 | ✅ Token 效率提升 |

#### 同义词扩展示例

**商品原文：** "Bolsa de silicone para armazenamento de alimentos"

**V1 提取（严格原文）：**
```
材质: ["silicone"]
用途: ["armazenamento de alimentos"]
```

**V2 提取（允许同义词）：**
```
材质: ["silicone", "silicone platina", "silicone alimentar"]
用途: ["armazenamento de alimentos", "guardar comida", "conservar alimentos"]
```

#### 解决的 V1 问题
- ✅ **问题 #4**：输入依赖非结构化输出
- ✅ **问题 #5**：防循环思考指令对非 CoT 模型无效
- ✅ **问题 #6**：原文约束过严，限制搜索覆盖

---

### Step 3: 三层吸引力词 → 三层搜索关键词（核心改进）

#### 改进内容

| 维度 | V1 | V2 | 改进效果 |
|------|----|----|---------|
| **指令长度** | ~190 行 | ~110 行 | ✅ **精简 42%** |
| **竞品分析框架** | 30 行，要求竞品差异分析 | 完全移除 | ✅ 消除幻觉风险 |
| **独特性判定** | 三级框架（高/中/低，~20 行） | 简化为优先级列表（3 行） | ✅ 可执行性提升 |
| **USP 选择逻辑** | "避免通用特性（密封、BPA Free）" | "用户高频搜索的功能词即使常见也值得保留" | ✅ 搜索友好 |
| **USP 数量** | 每个属性 1-2 个词 | 每个属性 2-3 个词 | ✅ 覆盖率提升 |
| **长尾词数量** | ≤4 个 | 5-6 个 | ✅ 长尾流量提升 |
| **长尾词约束** | "必须来自原文" | "允许别称、场景词、口语化表达" | ✅ 灵活性提升 |
| **指令矛盾** | 3 处矛盾 | 全部消除 | ✅ 输出一致性提升 |

#### 指令矛盾消除

**V1 的矛盾示例：**

| 矛盾类型 | V1 指令 A | V1 指令 B | 结果 |
|---------|----------|----------|------|
| brand 数量 | "brand 字段下只放 1 个词" | 示例中 `"brand":["優合", "Youha"]` 放了 2 个 | ❌ 模型困惑 |
| 创造新词 | "不要创造新词或组合词" | "可以对词提取，进行一定排列组合" | ❌ 直接矛盾 |
| 翻译策略 | "使用原文中的关键词，不要翻译" | "每个值都提供原语言和英文版本" | ❌ 逻辑不清 |

**V2 的解决方案：**

| 矛盾类型 | V2 解决方案 |
|---------|------------|
| brand 数量 | 明确说明："brand 字段可以包含品牌的不同语言版本（如中英文品牌名）" |
| 创造新词 | 统一为："允许同义词扩展，但不创造原文中不存在的语义" |
| 翻译策略 | 明确："所有关键词使用目标市场语言，`_en` 字段仅用于系统内部索引" |

#### USP 选择逻辑对比

**场景：** 硅胶食品储存袋的"密封性"特性

**V1 逻辑：**
```
❌ 避免通用特性：密封性是所有储存袋的基本特性，不应作为 USP
→ 结果：错失用户高频搜索词
```

**V2 逻辑：**
```
✅ 搜索导向：如果用户经常搜索"bolsa hermética"（密封袋），
   即使是常见特性也应保留
→ 结果：覆盖更多搜索路径
```

#### 解决的 V1 问题
- ✅ **问题 #7**：指令过长（190 行），认知负荷过高
- ✅ **问题 #8**：指令矛盾导致输出不一致（P0）
- ✅ **问题 #9**：竞品分析不现实，鼓励幻觉（P0）
- ✅ **问题 #10**：独特性分析框架过于学术化
- ✅ **问题 #11**：示例品类偏向（新增不同品类示例）

---

### Step 4: 候选评估

#### 改进内容

| 维度 | V1 | V2 | 改进效果 |
|------|----|----|---------|
| **评估维度** | 5 个（准确性 30%、完整性 25%、吸引力 25%、结构性 15%、简洁性 5%） | 4 个（语义准确性 30%、搜索覆盖 30%、完整性 25%、结构规范 15%） | ✅ 对齐搜索目标 |
| **核心变化** | "吸引力"评估表达是否生动 | "搜索覆盖"评估是否覆盖多种搜索路径 | ✅ 评估标准更客观 |
| **加权计算** | 未明确要求 | 明确给出加权公式 | ✅ 评分一致性提升 |
| **位置偏差** | 未处理 | 增加"不要受排列顺序影响"提醒 | ✅ 评估公正性提升 |
| **confidence** | 未定义 | 明确定义三级标准（high/medium/low） | ✅ 置信度可解释 |
| **简洁性** | 5%（几乎无意义） | 合并移除 | ✅ 权重分配合理 |

#### 评估维度对比

**V1 评估维度：**
```
准确性 (30%)：是否忠实于原文
完整性 (25%)：是否覆盖主要卖点
吸引力 (25%)：表达是否生动有吸引力  ← 与"忠实提取"矛盾
结构性 (15%)：JSON 结构是否规范
简洁性 (5%)：是否简洁不冗余  ← 权重过低
```

**V2 评估维度：**
```
语义准确性 (30%)：是否准确反映产品特性
搜索覆盖 (30%)：是否覆盖多种搜索路径  ← 对齐搜索目标
完整性 (25%)：是否覆盖主要卖点
结构规范 (15%)：JSON 结构是否规范
```

#### Confidence 定义

**V1：** 未定义，模型随意输出

**V2：** 明确三级标准
```
high：最佳候选明显优于其他（分差 > 0.5）
medium：最佳候选略优（分差 0.2-0.5）
low：多个候选质量接近（分差 < 0.2）
```

#### 解决的 V1 问题
- ✅ **问题 #14**：评估权重设计不合理
- ✅ **问题 #15**：缺少加权计算指令
- ✅ **问题 #16**：评估者位置偏差
- ✅ **问题 #18**：confidence 字段缺乏定义

---

## 🔍 跨步骤系统性改进

### 1. 语言策略明确化

**V1 问题：**
- Prompt 用简体中文，示例用繁体中文
- 未明确提取的关键词应该保持什么语言
- 多语言市场（如 MY、PH）处理不清晰

**V2 解决方案：**
```python
# 新增 Region → 语言映射
REGION_LANGUAGE_MAP = {
    "BR": ("Português (Brasil)", "Portuguese (Brazil)"),
    "TW": ("繁體中文", "Traditional Chinese"),
    "MY": ("Bahasa Melayu / English", "Malay / English"),
    ...
}

# 在每个 Step 的 prompt 中注入目标语言
目标市场语言：{target_language}
```

**效果：**
- ✅ 消除语言混用问题
- ✅ 多语言市场策略清晰
- ✅ 提取的关键词语言一致性提升

---

### 2. 边界情况处理

**V1 问题：** 未考虑边界情况

**V2 增加的边界处理：**

| 边界情况 | V2 处理策略 |
|---------|------------|
| 商品描述极短或为空 | "如果描述为空，仅基于标题和类目进行分析" |
| 可用 Schema 少于 5 个 | "如果可用属性不足 5 个，全部选择即可" |
| 某属性原文信息不足 | "如果某属性原文信息不足，可以不提取该属性的关键词" |
| 非标准品类 | 增加多品类示例（母婴、家居、电子等） |

**效果：**
- ✅ 鲁棒性提升
- ✅ 减少异常输出
- ✅ 适用品类范围扩大

---

### 3. Token 效率优化

**V1 Token 消耗：**
```
Step 1: ~800 tokens
Step 2: ~1200 tokens
Step 3: ~2200 tokens  ← 最大瓶颈
Step 4: ~1000 tokens
总计: ~5200 tokens/商品
```

**V2 Token 消耗：**
```
Step 1: ~700 tokens (-12.5%)
Step 2: ~1000 tokens (-16.7%)
Step 3: ~1400 tokens (-36.4%)  ← 核心优化
Step 4: ~900 tokens (-10%)
总计: ~4000 tokens/商品 (-23.1%)
```

**成本影响（以 10 万商品为例）：**
- V1: 5200 × 100,000 = 520M tokens
- V2: 4000 × 100,000 = 400M tokens
- **节省：** 120M tokens ≈ **节省 23% 成本**

---

## 📈 预期效果与风险

### 预期提升

| 指标 | V1 基线 | V2 预期 | 提升幅度 |
|------|--------|--------|---------|
| **搜索词覆盖率** | 基线 | +15% ~ +25% | 🔥 核心目标 |
| **一致率 (identical_rate)** | 35.8% (Gemini 2.5) | 30% ~ 35% | ⚠️ 可能下降 5-10% |
| **短语命中率 (hit_rate_phrase)** | 56.3% | 60% ~ 65% | ✅ 预期提升 |
| **单词命中率 (hit_rate_word)** | 96.6% | 96% ~ 97% | ➡️ 基本持平 |
| **FactScore（忠实度）** | 67.8% | 60% ~ 65% | ⚠️ 可能下降 5-10% |
| **输出一致性** | 基线 | +20% ~ +30% | ✅ 指令矛盾消除 |
| **处理速度** | 基线 | +15% ~ +20% | ✅ Token 减少 23% |

### 风险与权衡

#### 风险 1: FactScore 下降

**原因：** V2 允许同义词扩展，提取的词可能不出现在原文中

**示例：**
- 原文："Bolsa de silicone"
- V1 提取："silicone"（FactScore = 100%）
- V2 提取："silicone", "silicone platina"（FactScore = 50%，因为"platina"不在原文）

**应对策略：**
1. 在评估时同时监控 FactScore 和搜索覆盖率
2. 如果 FactScore 下降超过 15%，考虑调整同义词扩展的程度
3. 设置"同义词必须是该品类的常见表述"的约束

#### 风险 2: 一致率下降

**原因：** 同义词扩展导致与搜索词库的完全匹配减少

**权衡：** 这是预期的权衡。一致率下降但短语命中率提升，说明覆盖了更多搜索路径。

**评估标准调整：**
- V1 评估：一致率权重高
- V2 评估：短语命中率和单词命中率权重更高

#### 风险 3: 需要修改下游代码

**影响范围：**
- `processor.py` 需要修改 import：`from prompts_v2 import ...`
- Step 1 的 JSON 输出格式变化，需要适配解析逻辑
- 评估脚本可能需要调整权重

**建议：**
- 保留 V1 代码，通过配置开关切换版本
- 先在小规模数据集上 A/B 测试
- 逐步迁移到 V2

---

## 🧪 A/B 测试建议

### 测试方案

**测试集：** 500 条商品（与现有评估数据集相同）

**对比维度：**

| 维度 | 指标 | V1 基线 | V2 目标 |
|------|------|--------|--------|
| **搜索覆盖** | 短语命中率 | 56.3% | > 60% |
| **搜索覆盖** | 单词命中率 | 96.6% | > 96% |
| **忠实度** | FactScore | 67.8% | > 60% |
| **准确性** | 一致率 | 35.8% | > 30% |
| **效率** | 平均处理时间 | 基线 | < 85% |
| **稳定性** | 输出格式错误率 | 基线 | < 50% |

### 成功标准

**核心目标（必须达成）：**
- ✅ 短语命中率提升 > 5%
- ✅ 输出格式错误率下降 > 30%

**次要目标（尽量达成）：**
- ✅ FactScore 下降 < 10%
- ✅ 处理时间减少 > 10%

**失败标准（触发回滚）：**
- ❌ 短语命中率无提升或下降
- ❌ FactScore 下降 > 20%
- ❌ 输出格式错误率上升

---

## 📝 实施建议

### 阶段 1: 代码适配（1-2 天）

1. 修改 `processor.py` 的 import 逻辑，支持版本切换
2. 适配 Step 1 的 JSON 输出解析
3. 更新评估脚本的权重配置

### 阶段 2: 小规模测试（3-5 天）

1. 在 100 条商品上运行 V2
2. 人工检查输出质量
3. 对比 V1 和 V2 的指标差异
4. 调整 prompt 细节（如同义词扩展程度）

### 阶段 3: A/B 测试（1 周）

1. 在 500 条商品上运行 V1 和 V2
2. 生成对比报告（类似现有的 dashboard）
3. 分析指标变化，确认是否符合预期
4. 决定是否全量切换

### 阶段 4: 全量部署（根据测试结果）

1. 如果 A/B 测试成功，逐步切换到 V2
2. 保留 V1 作为降级方案
3. 持续监控线上指标

---

## 📊 改进总结

### 量化改进

| 改进项 | 量化指标 |
|--------|---------|
| **指令精简** | Step 3 从 190 行减少到 110 行（-42%） |
| **Token 效率** | 单商品处理从 5200 降至 4000 tokens（-23%） |
| **指令矛盾** | 从 3 处 P0 矛盾减少到 0 |
| **结构化程度** | 从 1/4 步骤 JSON 输出提升到 4/4 步骤 |
| **边界处理** | 从 0 条边界指导增加到 4 条 |

### 质量改进

| 改进项 | 效果 |
|--------|------|
| **搜索导向** | 从"忠实提取"转向"搜索友好"，预期搜索覆盖率提升 15-25% |
| **指令一致性** | 消除所有指令矛盾，输出一致性预期提升 20-30% |
| **可执行性** | 移除不现实的竞品分析要求，减少幻觉风险 |
| **鲁棒性** | 增加边界情况处理，适用品类范围扩大 |

### 成本改进

**以 10 万商品为例：**
- Token 节省：120M tokens
- 成本节省：约 **23%**（具体取决于 API 定价）
- 处理时间：预期减少 **15-20%**

---

## 🎯 下一步行动

### 立即行动（本周）

1. ✅ **代码适配**：修改 `processor.py` 支持 V2
2. ✅ **小规模测试**：在 100 条商品上验证 V2 输出质量
3. ✅ **人工评估**：检查同义词扩展是否合理

### 短期行动（下周）

1. 📊 **A/B 测试**：在 500 条商品上对比 V1 vs V2
2. 📈 **生成报告**：创建类似 `ksp_eval_dashboard.html` 的对比 dashboard
3. 🔍 **指标分析**：重点关注搜索覆盖率和 FactScore 的权衡

### 中期行动（2-4 周）

1. 🚀 **全量部署**：根据 A/B 测试结果决定是否切换
2. 📝 **文档更新**：更新 README 和 API 文档
3. 🔄 **持续优化**：根据线上反馈微调 prompt

---

## 📎 附录

### 附录 A: V1 问题清单（22 个）

详见 `prompts_analysis.md` 第四章节。

### 附录 B: V2 完整代码

位置：`prompts_v2.py`

### 附录 C: 评估数据

现有评估数据：
- `docs/ksp_eval_dashboard.html` - 7 个模型在 500 条数据上的表现
- `docs/gemini_7b_ksp_compare.html` - Gemini 2.5 Flash vs Qwen2.5-7B 对比

---

**报告编制：** AI Assistant  
**审核建议：** 建议由项目负责人审核后进行 A/B 测试  
**联系方式：** 如有疑问请查看项目 README 或相关文档
